{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precursor\n",
    "This was run on Google's Colab, which is why the training files and testing files are being loaded from the Drive.\n",
    "\n",
    "Code below is to be able to access files in Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "- CNN with two 32 filter convolution layers and two 64 filter convolution layers\n",
    "- Training data can be augmented to try and increase the sample size as a small sample size is used as training\n",
    "- Some of the results of the are written in the comments at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "###############\n",
    "## WITH DATA AUG\n",
    "# 0 rotate, 0.1 hori vert shift, 0 zoom:\n",
    "# loss: 0.6865 - acc: 0.7812 - val_loss: 0.4656 - val_acc: 0.8684 # USED THIS\n",
    "# 30 rotate, 0.2 hori vert shift, 0.1 zoom:\n",
    "# loss: 0.7520 - acc: 0.7368 - val_loss: 0.6760 - val_acc: 0.7961\n",
    "## WITHOUT DATA AUG\n",
    "# 0 rotate, 0.1 hori vert shift, 0 zoom:\n",
    "# loss: 0.1997 - acc: 0.9457 - val_loss: 1.0672 - val_acc: 0.7171\n",
    "# 30 rotate, 0.2 hori vert shift, 0.1 zoom:\n",
    "# loss: 0.0930 - acc: 0.9737 - val_loss: 1.0791 - val_acc: 0.7566\n",
    "###############\n",
    "\n",
    "X_train = np.load(\n",
    "    \"drive/My Drive/Colab Notebooks/syde 522 Kaggle Challenge/train_x.npy\")\n",
    "Y_train = np.load(\n",
    "    \"drive/My Drive/Colab Notebooks/syde 522 Kaggle Challenge/train_label.npy\")\n",
    "X_test = np.load(\n",
    "    \"drive/My Drive/Colab Notebooks/syde 522 Kaggle Challenge/test_x.npy\")\n",
    "\n",
    "NUM_CLASSES = 20\n",
    "augment = True\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Normalize\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(34, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Define the optimizer\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if augment:\n",
    "  # Augment the data\n",
    "  datagen = ImageDataGenerator(\n",
    "      featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "      samplewise_center=False,  # set each sample mean to 0\n",
    "      featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "      samplewise_std_normalization=False,  # divide each input by its std\n",
    "      zca_whitening=False,  # apply ZCA whitening\n",
    "      zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "      # randomly rotate images in the range (degrees, 0 to 180)\n",
    "      rotation_range=0,\n",
    "      # randomly shift images horizontally (fraction of total width)\n",
    "      width_shift_range=0.1,\n",
    "      # randomly shift images vertically (fraction of total height)\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.,  # set range for random shear\n",
    "      zoom_range=0.,  # set range for random zoom\n",
    "      channel_shift_range=0.,  # set range for random channel shifts\n",
    "      # set mode for filling points outside the input boundaries\n",
    "      fill_mode='nearest',\n",
    "      cval=0.,  # value used for fill_mode = \"constant\"\n",
    "      horizontal_flip=True,  # randomly flip images\n",
    "      vertical_flip=False,  # randomly flip images\n",
    "      # set rescaling factor (applied before any other transformation)\n",
    "      rescale=None,\n",
    "      # set function that will be applied on each input\n",
    "      preprocessing_function=None,\n",
    "      # image data format, either \"channels_first\" or \"channels_last\"\n",
    "      data_format=None,\n",
    "      # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "      validation_split=0.0)\n",
    "\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(X_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "  model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                                   batch_size=BATCH_SIZE),\n",
    "                      epochs=EPOCHS,\n",
    "                      steps_per_epoch=np.ceil(len(X_train) / BATCH_SIZE),\n",
    "                      validation_data=(X_val, Y_val),\n",
    "                      workers=4)\n",
    "else:\n",
    "  model.fit(X_train, Y_train,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(X_val, Y_val),\n",
    "            shuffle=True)\n",
    "\n",
    "results = model.predict(X_test)\n",
    "results = np.argmax(results, axis=1)\n",
    "results = pd.Series(results, name='Predicted')\n",
    "\n",
    "submission = pd.concat([pd.Series(range(0, 200), name='Id'), results], axis=1)\n",
    "\n",
    "submission.to_csv(\n",
    "    \"drive/My Drive/Colab Notebooks/syde 522 Kaggle Challenge/cnn_predicted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Model\n",
    "- CNN with using Keras' pretrained ResNet50 Model\n",
    "- Training data is not augmented because it lowered the val_acc and increased the val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.load(\n",
    "    \"drive/My Drive/Colab Notebooks/syde 522 Kaggle Challenge/train_x.npy\")\n",
    "Y_train = np.load(\n",
    "    \"drive/My Drive/Colab Notebooks/syde 522 Kaggle Challenge/train_label.npy\")\n",
    "X_test = np.load(\n",
    "    \"drive/My Drive/Colab Notebooks/syde 522 Kaggle Challenge/test_x.npy\")\n",
    "\n",
    "NUM_CLASSES = 20\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# Normalize\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "INPUT_SHAPE = X_train.shape[1:]\n",
    "\n",
    "# Set the CNN model - Using ResNet\n",
    "base = ResNet50(input_shape=INPUT_SHAPE, include_top=False, weights='imagenet')\n",
    "x = base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "pred = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "model = Model(inputs=base.input, output=pred)\n",
    "\n",
    "# Define the optimizer\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# reduce the learning rate by half when the val_acc plateaus\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "# early stop when val_loss doesnt decrease past baseline\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           verbose=1,\n",
    "                           mode='min',\n",
    "                           baseline=0.05,\n",
    "                           patience=5)\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(X_val, Y_val),\n",
    "          shuffle=True,\n",
    "          callbacks=[learning_rate_reduction, early_stop])\n",
    "\n",
    "# Get results and write to csv\n",
    "results = model.predict(X_test)\n",
    "results = np.argmax(results, axis=1)\n",
    "results = pd.Series(results, name='Predicted')\n",
    "\n",
    "submission = pd.concat([pd.Series(range(0, 200), name='Id'), results], axis=1)\n",
    "\n",
    "submission.to_csv(\n",
    "    \"drive/My Drive/Colab Notebooks/syde 522 Kaggle Challenge/cnn_predicted.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
